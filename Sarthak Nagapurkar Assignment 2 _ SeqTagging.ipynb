{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6b970e",
   "metadata": {},
   "source": [
    "### Sequence Tagging on Treebank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e21f8e16-f405-4852-b555-bcb114be567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914 [('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "3000 414 500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import nltk\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# Download the necessary nltk resources\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "# Load the POS-tagged Penn Treebank sentences\n",
    "tagged_sentences = treebank.tagged_sents()\n",
    "print(len(tagged_sentences), tagged_sentences[0])\n",
    "\n",
    "train_tagged_sentences = tagged_sentences[:3000]\n",
    "valid_tagged_sentences = tagged_sentences[3000:3414]\n",
    "test_tagged_sentences = tagged_sentences[3414:]\n",
    "\n",
    "print(len(train_tagged_sentences), len(valid_tagged_sentences), len(test_tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "835db40e-1ca9-4b56-bdf1-14f391521252",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Process, Batch, Dataloader\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Build word vocabulary\n",
    "def yield_tokens(data_iter):\n",
    "    for sentence in data_iter:\n",
    "        yield [word for word, tag in sentence]\n",
    "\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(yield_tokens(tagged_sentences), specials=['<unk>', '<pad>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "# Build tag vocabulary (based on the tags in the dataset)\n",
    "pos_tags = list(set(tag for sentence in tagged_sentences for word, tag in sentence))\n",
    "tag_vocab = {tag: i for i, tag in enumerate(pos_tags)}\n",
    "tag_vocab['<pad>'] = len(tag_vocab)  # Add a pad token\n",
    "\n",
    "# Process each sentence to get word indices and POS tag indices\n",
    "def process_sentence_with_tags(sentence):\n",
    "    words, tags = zip(*sentence)  # Unzip the sentence into words and tags\n",
    "    word_indices = [vocab[token] for token in words]  # Convert words to indices\n",
    "    tag_indices = [tag_vocab[tag] for tag in tags] # Convert tags to indices\n",
    "    return word_indices, tag_indices\n",
    "\n",
    "# Collate function for batching and padding\n",
    "def collate_batch(batch):\n",
    "    text_list, tag_list = [], []\n",
    "    \n",
    "    for sentence in batch:\n",
    "        word_indices, tag_indices = process_sentence_with_tags(sentence)\n",
    "        text_list.append(torch.tensor(word_indices, dtype=torch.int64))\n",
    "        tag_list.append(torch.tensor(tag_indices, dtype=torch.int64))\n",
    "\n",
    "    # Pad sequences\n",
    "    text_padded = pad_sequence(text_list, batch_first=True, padding_value=vocab['<pad>'])\n",
    "    tag_padded = pad_sequence(tag_list, batch_first=True, padding_value=tag_vocab['<pad>'])\n",
    "    \n",
    "    return text_padded, tag_padded\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_tagged_sentences, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(valid_tagged_sentences, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_tagged_sentences, batch_size=32, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38ce88-7210-4b44-9b43-23e8c56a3fd1",
   "metadata": {},
   "source": [
    "### Add pre-trained GloVe (50d) embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46ec0ae9-f3b1-4a0a-b07c-8dd9e6e4c204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_28608\\2652793300.py:5: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  glove_file = 'glove.6B\\glove.6B\\glove.6B.50d.txt'  # Change path as needed\n"
     ]
    }
   ],
   "source": [
    "#Use pre-trained word embeddings from GloVe. \n",
    "\n",
    "import numpy as np\n",
    "# Path to the GloVe file\n",
    "glove_file = 'glove.6B\\glove.6B\\glove.6B.50d.txt'  # Change path as needed\n",
    "#glove_file = 'FastText_PCA_reduced-vectors.txt\\FastText_PCA_reduced-vectors.txt'  # Change path as needed\n",
    "# Initialize an empty dictionary\n",
    "embeddings_index = {}\n",
    "\n",
    "# Load the GloVe vectors\n",
    "with open(glove_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50\n",
    "\n",
    "# Initialize the embedding matrix (vocab_size x embedding_dim)\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Fill the embedding matrix with GloVe vectors\n",
    "for word, i in train_dataloader:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88a7bac1-ca7f-48e8-8905-32efc34b6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, num_tags, dropout_prob=0.5):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = True\n",
    "\n",
    "        # Layer normalization after LSTM\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout after embedding layer\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_tags)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x: [batch_size, seq_len]\n",
    "        \n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embed_size]\n",
    "        x = self.dropout(x)  # Apply dropout after embedding\n",
    "\n",
    "        out, hidden = self.lstm(x, hidden)  # [batch_size, seq_len, hidden_size]\n",
    "        out = self.layer_norm(out)  # Apply layer normalization\n",
    "        \n",
    "        out = self.dropout(out)  # Apply dropout after LSTM output\n",
    "\n",
    "        out = self.fc(out)  # [batch_size, seq_len, num_tags]\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize LSTM hidden state (h_0, c_0)\n",
    "        h_0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        c_0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        return (h_0, c_0)\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 50\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_tags = len(tag_vocab)\n",
    "num_epochs = 20\n",
    "lr = 0.01\n",
    "dropout_prob = 0.3\n",
    "\n",
    "# Initialize the model with fine-tuning and dropout\n",
    "model = LSTMTagger(vocab_size=vocab_size, embed_size=embed_size, hidden_size=hidden_size, \n",
    "                   num_layers=num_layers, num_tags=num_tags, \n",
    "                   dropout_prob=dropout_prob)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89d3d55e-37b0-431b-98c6-b06f52839cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sequence_tagging(model, dataloader, optimizer, criterion, epoch):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch, (data, targets) in enumerate(dataloader):\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients from previous batch\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        # Initialize hidden and cell states for LSTM\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "\n",
    "        # Forward pass through the LSTM model\n",
    "        output, hidden = model(data, hidden)  # Output shape: [batch_size, seq_len, num_tags]\n",
    "\n",
    "        # Reshape output and targets for loss calculation\n",
    "        output = output.view(-1, num_tags)  # [batch_size * seq_len, num_tags]\n",
    "        targets = targets.view(-1)  # [batch_size * seq_len]\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()  # Backpropagation to compute gradients\n",
    "        optimizer.step()  # Update the model parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Get predicted tags (using argmax to get the predicted tag indices)\n",
    "        predicted_tags = torch.argmax(output, dim=1)\n",
    "\n",
    "        # Ignore padding tokens in accuracy calculation\n",
    "        non_pad_elements = (targets != tag_vocab['<pad>']).nonzero(as_tuple=True)\n",
    "\n",
    "        # Calculate the number of correct predictions\n",
    "        correct_predictions += (predicted_tags[non_pad_elements] == targets[non_pad_elements]).sum().item()\n",
    "\n",
    "        # Count the number of non-pad tokens\n",
    "        total_predictions += max(len(non_pad_elements[0]), len((predicted_tags != tag_vocab['<pad>']).nonzero(as_tuple=True)[0]))\n",
    "\n",
    "        batch_count += 1\n",
    "\n",
    "        # Print intermediate training statistics every 20 batches\n",
    "        if batch_count % 20 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Batch [{batch_count}], Loss: {loss.item():.4f}, Accuracy: {correct_predictions / total_predictions:.4f}')\n",
    "\n",
    "    # Compute average loss and accuracy over the entire epoch\n",
    "    avg_loss = total_loss / batch_count\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Train Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e586a58f-4cf4-4517-b955-3128c66b241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_hidden(self, batch_size):\n",
    "    # Return two tensors (hidden state and cell state) of the correct size for LSTM\n",
    "    return (torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "            torch.zeros(num_layers, batch_size, hidden_size).to(device))\n",
    "\n",
    "def evaluate_and_store_examples(model, dataloader, criterion, vocab, tag_vocab, num_examples=5):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    batch_count = 0\n",
    "    examples = []  # List to store examples\n",
    "\n",
    "    # Reverse the vocab and tag_vocab for easier lookup\n",
    "    idx_to_word = {i: word for word, i in vocab.get_stoi().items()}\n",
    "    idx_to_tag = {i: tag for tag, i in tag_vocab.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "            batch_size = data.size(0)\n",
    "            seq_len = data.size(1)\n",
    "\n",
    "            # Initialize hidden and cell states for LSTM\n",
    "            hidden = model.init_hidden(batch_size)\n",
    "\n",
    "            # Forward pass through the model\n",
    "            output, hidden = model(data, hidden)  # hidden is (h_n, c_n) for LSTM\n",
    "\n",
    "            # Reshape output and targets for computing loss\n",
    "            output = output.view(-1, num_tags)  # [batch_size * seq_len, num_tags]\n",
    "            targets = targets.view(-1)  # [batch_size * seq_len]\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Get predicted tags\n",
    "            predicted_tags = torch.argmax(output, dim=1)\n",
    "\n",
    "            # Ignore padding tokens in accuracy calculation\n",
    "            non_pad_elements_target = (targets != tag_vocab['<pad>']).nonzero(as_tuple=True)\n",
    "            non_pad_elements_predicted = (predicted_tags != tag_vocab['<pad>']).nonzero(as_tuple=True)\n",
    "\n",
    "            # Calculate number of correct predictions (between predicted and actual tags, ignoring <pad>)\n",
    "            if len(non_pad_elements_predicted[0]) > len(non_pad_elements_target[0]):\n",
    "                correct_predictions += (predicted_tags[non_pad_elements_predicted] == targets[non_pad_elements_predicted]).sum().item()\n",
    "                total_predictions += len(non_pad_elements_predicted[0])  # Number of non-pad tokens\n",
    "            else:\n",
    "                correct_predictions += (predicted_tags[non_pad_elements_target] == targets[non_pad_elements_target]).sum().item()\n",
    "                total_predictions += len(non_pad_elements_target[0])  # Number of non-pad tokens\n",
    "\n",
    "            # Store sample predictions (only store a few examples, controlled by num_examples)\n",
    "            if len(examples) < num_examples:\n",
    "                for i in range(min(5, batch_size)):  # Store up to 5 sentences from each batch\n",
    "                    sentence_words = [idx_to_word[idx.item()] for idx in data[i] if idx != vocab['<pad>']]\n",
    "                    true_tags = [idx_to_tag[idx.item()] for idx in targets[i * seq_len:(i + 1) * seq_len] if idx != tag_vocab['<pad>']]\n",
    "                    pred_tags = [idx_to_tag[idx.item()] for idx in predicted_tags[i * seq_len:(i + 1) * seq_len] if idx != tag_vocab['<pad>']]\n",
    "\n",
    "                    # Store the example as a tuple (sentence, predicted tags, true tags)\n",
    "                    examples.append((sentence_words, pred_tags, true_tags))\n",
    "\n",
    "            batch_count += 1\n",
    "            if len(examples) >= num_examples:\n",
    "                break  # Stop collecting examples once we've reached the desired number\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = total_loss / batch_count\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Evaluation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return avg_loss, accuracy, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f22ac94d-10e7-4d23-a133-4f46f5a6b3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Batch [20], Loss: 1.4798, Accuracy: 0.0418\n",
      "Epoch [1/20], Batch [40], Loss: 0.9104, Accuracy: 0.1379\n",
      "Epoch [1/20], Batch [60], Loss: 0.7660, Accuracy: 0.2463\n",
      "Epoch [1/20], Batch [80], Loss: 0.4539, Accuracy: 0.3389\n",
      "Train Loss: 1.0949, Accuracy: 0.3944\n",
      "Evaluation Loss: 0.3325, Accuracy: 0.7593\n",
      "Epoch [2/20], Batch [20], Loss: 0.1294, Accuracy: 0.8128\n",
      "Epoch [2/20], Batch [40], Loss: 0.2513, Accuracy: 0.8278\n",
      "Epoch [2/20], Batch [60], Loss: 0.2211, Accuracy: 0.8398\n",
      "Epoch [2/20], Batch [80], Loss: 0.2362, Accuracy: 0.8477\n",
      "Train Loss: 0.2505, Accuracy: 0.8549\n",
      "Evaluation Loss: 0.2094, Accuracy: 0.8490\n",
      "Epoch [3/20], Batch [20], Loss: 0.1047, Accuracy: 0.9290\n",
      "Epoch [3/20], Batch [40], Loss: 0.1749, Accuracy: 0.9290\n",
      "Epoch [3/20], Batch [60], Loss: 0.1711, Accuracy: 0.9291\n",
      "Epoch [3/20], Batch [80], Loss: 0.1366, Accuracy: 0.9310\n",
      "Train Loss: 0.1184, Accuracy: 0.9318\n",
      "Evaluation Loss: 0.2309, Accuracy: 0.8519\n",
      "Epoch [4/20], Batch [20], Loss: 0.0730, Accuracy: 0.9530\n",
      "Epoch [4/20], Batch [40], Loss: 0.0706, Accuracy: 0.9513\n",
      "Epoch [4/20], Batch [60], Loss: 0.0711, Accuracy: 0.9507\n",
      "Epoch [4/20], Batch [80], Loss: 0.1051, Accuracy: 0.9517\n",
      "Train Loss: 0.0851, Accuracy: 0.9514\n",
      "Evaluation Loss: 0.2332, Accuracy: 0.8561\n",
      "Epoch [5/20], Batch [20], Loss: 0.0950, Accuracy: 0.9601\n",
      "Epoch [5/20], Batch [40], Loss: 0.0699, Accuracy: 0.9599\n",
      "Epoch [5/20], Batch [60], Loss: 0.0627, Accuracy: 0.9594\n",
      "Epoch [5/20], Batch [80], Loss: 0.0626, Accuracy: 0.9596\n",
      "Train Loss: 0.0691, Accuracy: 0.9592\n",
      "Evaluation Loss: 0.2743, Accuracy: 0.8433\n",
      "Epoch [6/20], Batch [20], Loss: 0.0801, Accuracy: 0.9653\n",
      "Epoch [6/20], Batch [40], Loss: 0.0533, Accuracy: 0.9651\n",
      "Epoch [6/20], Batch [60], Loss: 0.0801, Accuracy: 0.9654\n",
      "Epoch [6/20], Batch [80], Loss: 0.0692, Accuracy: 0.9645\n",
      "Train Loss: 0.0615, Accuracy: 0.9639\n",
      "Evaluation Loss: 0.2575, Accuracy: 0.8490\n",
      "Epoch [7/20], Batch [20], Loss: 0.0564, Accuracy: 0.9682\n",
      "Epoch [7/20], Batch [40], Loss: 0.0543, Accuracy: 0.9674\n",
      "Epoch [7/20], Batch [60], Loss: 0.0381, Accuracy: 0.9680\n",
      "Epoch [7/20], Batch [80], Loss: 0.0517, Accuracy: 0.9676\n",
      "Train Loss: 0.0539, Accuracy: 0.9674\n",
      "Evaluation Loss: 0.2937, Accuracy: 0.8490\n",
      "Epoch [8/20], Batch [20], Loss: 0.0445, Accuracy: 0.9711\n",
      "Epoch [8/20], Batch [40], Loss: 0.0407, Accuracy: 0.9704\n",
      "Epoch [8/20], Batch [60], Loss: 0.0580, Accuracy: 0.9698\n",
      "Epoch [8/20], Batch [80], Loss: 0.0597, Accuracy: 0.9691\n",
      "Train Loss: 0.0502, Accuracy: 0.9689\n",
      "Evaluation Loss: 0.2807, Accuracy: 0.8533\n",
      "Epoch [9/20], Batch [20], Loss: 0.0676, Accuracy: 0.9663\n",
      "Epoch [9/20], Batch [40], Loss: 0.0445, Accuracy: 0.9677\n",
      "Epoch [9/20], Batch [60], Loss: 0.0327, Accuracy: 0.9686\n",
      "Epoch [9/20], Batch [80], Loss: 0.0344, Accuracy: 0.9686\n",
      "Train Loss: 0.0488, Accuracy: 0.9690\n",
      "Evaluation Loss: 0.2821, Accuracy: 0.8590\n",
      "Epoch [10/20], Batch [20], Loss: 0.0522, Accuracy: 0.9686\n",
      "Epoch [10/20], Batch [40], Loss: 0.0393, Accuracy: 0.9703\n",
      "Epoch [10/20], Batch [60], Loss: 0.0375, Accuracy: 0.9705\n",
      "Epoch [10/20], Batch [80], Loss: 0.0471, Accuracy: 0.9704\n",
      "Train Loss: 0.0465, Accuracy: 0.9706\n",
      "Evaluation Loss: 0.2553, Accuracy: 0.8632\n",
      "Epoch [11/20], Batch [20], Loss: 0.0414, Accuracy: 0.9739\n",
      "Epoch [11/20], Batch [40], Loss: 0.0605, Accuracy: 0.9731\n",
      "Epoch [11/20], Batch [60], Loss: 0.0418, Accuracy: 0.9734\n",
      "Epoch [11/20], Batch [80], Loss: 0.0601, Accuracy: 0.9728\n",
      "Train Loss: 0.0443, Accuracy: 0.9724\n",
      "Evaluation Loss: 0.2681, Accuracy: 0.8547\n",
      "Epoch [12/20], Batch [20], Loss: 0.0455, Accuracy: 0.9740\n",
      "Epoch [12/20], Batch [40], Loss: 0.0375, Accuracy: 0.9736\n",
      "Epoch [12/20], Batch [60], Loss: 0.0461, Accuracy: 0.9736\n",
      "Epoch [12/20], Batch [80], Loss: 0.0367, Accuracy: 0.9734\n",
      "Train Loss: 0.0410, Accuracy: 0.9735\n",
      "Evaluation Loss: 0.2637, Accuracy: 0.8604\n",
      "Epoch [13/20], Batch [20], Loss: 0.0391, Accuracy: 0.9719\n",
      "Epoch [13/20], Batch [40], Loss: 0.0450, Accuracy: 0.9738\n",
      "Epoch [13/20], Batch [60], Loss: 0.0554, Accuracy: 0.9734\n",
      "Epoch [13/20], Batch [80], Loss: 0.0452, Accuracy: 0.9731\n",
      "Train Loss: 0.0404, Accuracy: 0.9736\n",
      "Evaluation Loss: 0.2727, Accuracy: 0.8704\n",
      "Epoch [14/20], Batch [20], Loss: 0.0420, Accuracy: 0.9760\n",
      "Epoch [14/20], Batch [40], Loss: 0.0412, Accuracy: 0.9759\n",
      "Epoch [14/20], Batch [60], Loss: 0.0459, Accuracy: 0.9760\n",
      "Epoch [14/20], Batch [80], Loss: 0.0238, Accuracy: 0.9756\n",
      "Train Loss: 0.0385, Accuracy: 0.9754\n",
      "Evaluation Loss: 0.2767, Accuracy: 0.8675\n",
      "Epoch [15/20], Batch [20], Loss: 0.0361, Accuracy: 0.9765\n",
      "Epoch [15/20], Batch [40], Loss: 0.0345, Accuracy: 0.9749\n",
      "Epoch [15/20], Batch [60], Loss: 0.0368, Accuracy: 0.9749\n",
      "Epoch [15/20], Batch [80], Loss: 0.0317, Accuracy: 0.9755\n",
      "Train Loss: 0.0369, Accuracy: 0.9754\n",
      "Evaluation Loss: 0.2993, Accuracy: 0.8561\n",
      "Epoch [16/20], Batch [20], Loss: 0.0215, Accuracy: 0.9762\n",
      "Epoch [16/20], Batch [40], Loss: 0.0336, Accuracy: 0.9764\n",
      "Epoch [16/20], Batch [60], Loss: 0.0427, Accuracy: 0.9764\n",
      "Epoch [16/20], Batch [80], Loss: 0.0416, Accuracy: 0.9765\n",
      "Train Loss: 0.0368, Accuracy: 0.9759\n",
      "Evaluation Loss: 0.2923, Accuracy: 0.8590\n",
      "Epoch [17/20], Batch [20], Loss: 0.0365, Accuracy: 0.9773\n",
      "Epoch [17/20], Batch [40], Loss: 0.0237, Accuracy: 0.9771\n",
      "Epoch [17/20], Batch [60], Loss: 0.0332, Accuracy: 0.9764\n",
      "Epoch [17/20], Batch [80], Loss: 0.0318, Accuracy: 0.9763\n",
      "Train Loss: 0.0360, Accuracy: 0.9761\n",
      "Evaluation Loss: 0.3355, Accuracy: 0.8618\n",
      "Epoch [18/20], Batch [20], Loss: 0.0290, Accuracy: 0.9783\n",
      "Epoch [18/20], Batch [40], Loss: 0.0222, Accuracy: 0.9779\n",
      "Epoch [18/20], Batch [60], Loss: 0.0263, Accuracy: 0.9772\n",
      "Epoch [18/20], Batch [80], Loss: 0.0390, Accuracy: 0.9767\n",
      "Train Loss: 0.0353, Accuracy: 0.9769\n",
      "Evaluation Loss: 0.3006, Accuracy: 0.8590\n",
      "Epoch [19/20], Batch [20], Loss: 0.0198, Accuracy: 0.9783\n",
      "Epoch [19/20], Batch [40], Loss: 0.0272, Accuracy: 0.9775\n",
      "Epoch [19/20], Batch [60], Loss: 0.0368, Accuracy: 0.9777\n",
      "Epoch [19/20], Batch [80], Loss: 0.0377, Accuracy: 0.9779\n",
      "Train Loss: 0.0332, Accuracy: 0.9780\n",
      "Evaluation Loss: 0.3216, Accuracy: 0.8632\n",
      "Epoch [20/20], Batch [20], Loss: 0.0235, Accuracy: 0.9777\n",
      "Epoch [20/20], Batch [40], Loss: 0.0363, Accuracy: 0.9777\n",
      "Epoch [20/20], Batch [60], Loss: 0.0279, Accuracy: 0.9774\n",
      "Epoch [20/20], Batch [80], Loss: 0.0421, Accuracy: 0.9774\n",
      "Train Loss: 0.0332, Accuracy: 0.9770\n",
      "Evaluation Loss: 0.3231, Accuracy: 0.8533\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, acc = train_sequence_tagging(model, train_dataloader, optimizer, criterion, epoch)\n",
    "    valid_loss, valid_accuracy, examples = evaluate_and_store_examples(model, valid_dataloader, criterion, vocab, tag_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cef09f82-e0be-45ea-9a1e-038a1eaa5328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.1700, Accuracy: 0.9213\n",
      "\n",
      "Print Example Predictions:\n",
      "\n",
      "Example 1:\n",
      "Sentence: An index of economic activity drawn * from the survey stood last month at 47.6 % ; a reading above 50 % would have indicated that the manufacturing sector was improving .\n",
      "Pred Tags: DT NN IN JJ NN VBN -NONE- IN DT NN VBD JJ NN IN CD NN : DT NN IN CD NN MD VB VBN IN DT NN NN VBD VBG .\n",
      "True Tags: DT NN IN JJ NN VBN -NONE- IN DT NN VBD JJ NN IN CD NN : DT NN IN CD NN MD VB VBN IN DT VBG NN VBD VBG .\n",
      "\n",
      "Example 2:\n",
      "Sentence: But with the index proving somewhat better than * expected and the widely anticipated report on October employment scheduled *-1 to arrive tomorrow , stock prices firmed only modestly in response to the report and then faltered .\n",
      "Pred Tags: CC IN DT NN VBG NN RBR IN -NONE- VBN CC DT RB VBN NN IN NNP NN VBN -NONE- TO VB JJ , NN NNS VBP RB RB IN NN TO DT NN CC RB VBN .\n",
      "True Tags: CC IN DT NN VBG RB JJR IN -NONE- VBN CC DT RB VBN NN IN NNP NN VBN -NONE- TO VB NN , NN NNS VBD RB RB IN NN TO DT NN CC RB VBD .\n",
      "\n",
      "Example 3:\n",
      "Sentence: `` This market 's still going through its pains , '' said *T*-1 Philip Puccio , head of equity trading at Prudential-Bache Securities .\n",
      "Pred Tags: `` DT NN POS RB VBG IN PRP$ NN , '' VBD -NONE- NNP NNP , NN IN NN NN IN NNP NNPS .\n",
      "True Tags: `` DT NN VBZ RB VBG IN PRP$ NNS , '' VBD -NONE- NNP NNP , NN IN NN NN IN NNP NNPS .\n",
      "\n",
      "Example 4:\n",
      "Sentence: `` The psychology is still : ` We want -LRB- stocks -RRB- up , but if they do n't carry we 're going *-1 to sell them . ' ''\n",
      "Pred Tags: `` DT NN VBZ RB : `` PRP VBP -LRB- NNS -RRB- IN , CC IN PRP VBP RB VB PRP VBP VBG -NONE- TO VB PRP . '' ''\n",
      "True Tags: `` DT NN VBZ RB : `` PRP VBP -LRB- NNS -RRB- RB , CC IN PRP VBP RB VB PRP VBP VBG -NONE- TO VB PRP . '' ''\n",
      "\n",
      "Example 5:\n",
      "Sentence: Uncertainty about the prospects for further action * to curtail stock-index arbitrage , a form of program trading blamed * for recent volatility in the market , also contributed to its lack of direction , Mr. Puccio said 0 *T*-1 .\n",
      "Pred Tags: NN IN DT NNS IN JJ NN -NONE- TO VB JJ NN , DT NN IN NN NN VBN -NONE- IN JJ NN IN DT NN , RB VBD TO PRP$ NN IN NN , NNP NNP VBD -NONE- -NONE- .\n",
      "True Tags: NN IN DT NNS IN JJ NN -NONE- TO VB JJ NN , DT NN IN NN NN VBN -NONE- IN JJ NN IN DT NN , RB VBD TO PRP$ NN IN NN , NNP NNP VBD -NONE- -NONE- .\n"
     ]
    }
   ],
   "source": [
    "# test performance\n",
    "test_loss, test_accuracy, examples = evaluate_and_store_examples(model, test_dataloader, criterion, vocab, tag_vocab)\n",
    "\n",
    "print(\"\\nPrint Example Predictions:\")\n",
    "for i, (sentence, pred_tags, true_tags) in enumerate(examples):\n",
    "    print(f\"\\nExample {i + 1}:\")\n",
    "    print(f\"Sentence: {' '.join(sentence)}\")\n",
    "    print(f\"Pred Tags: {' '.join(pred_tags)}\")\n",
    "    print(f\"True Tags: {' '.join(true_tags)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
